{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Trees: Ensemble Methods - Random Forest\n",
    "\n",
    "*Bagging to decrease the model’s variance;*\n",
    "\n",
    "With Random Forest in addition to taking the random subset of data, it also takes the random selection of features rather than using all features to grow trees. When you have many random trees. It’s called Random Forest.\n",
    "\n",
    "With Random Forest, our goal is to reduce the variance of a decision Tree. We end up with an ensemble of different models. Average of all the predictions from different trees are used which is more robust than a single decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1., 1.])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "\n",
    "X,y = load_iris(return_X_y=True)\n",
    "\n",
    "#train,test split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42)\n",
    "\n",
    "#random forest with gini\n",
    "rf = RandomForestClassifier(criterion='gini',n_estimators=150,max_depth=4,n_jobs=-1)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "rf_predict = rf.predict(X_test)\n",
    "\n",
    "f1_score(y_test, rf_predict, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1., 1.])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest with gini\n",
    "rf = RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=4,n_jobs=-1)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "rf_predict = rf.predict(X_test)\n",
    "\n",
    "f1_score(y_test, rf_predict, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Can you get a better mean absolute error compared to the random forest used at https://shoe-size-predict.herokuapp.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}